data = {
  "nodes": [{"id": "gibbs_inequality"},{"id": "numpy"},{"id": "unix"},{"id": "sufficient_statistics"},{"id": "gibbs_sampling"},{"id": "bayesian_inference"},{"id": "the_art_of_unix_programming"},{"id": "the_art_of_doing_science_and_engineering"},{"id": "machine_teaching"},{"id": "options_framework"},{"id": "progressive_summarization"},{"id": "probability_theory"},{"id": "gpipe"},{"id": "negotiation"},{"id": "odometry_motion_model"},{"id": "are_we_smart_enough_to_know_how_smart_animals_are"},{"id": "markov_decision_process"},{"id": "finance"},{"id": "2020-01-30"},{"id": "cognitive_hierarchy_model"},{"id": "reinforcement_learning"},{"id": "slice_sampling"},{"id": "spiking_neurons_lit_review"},{"id": "java"},{"id": "arm"},{"id": "coding_interview"},{"id": "topic_modelling"},{"id": "hopfield_network"},{"id": "compilers"},{"id": "model_based_rl"},{"id": "investing_in_etfs"},{"id": "networking"},{"id": "gaussian_filter"},{"id": "scala"},{"id": "particle_filter"},{"id": "robot_localization"},{"id": "markov_chains"},{"id": "pc_building"},{"id": "programming_methodology"},{"id": "occams_razor"},{"id": "spiking_datasets"},{"id": "neural_ode"},{"id": "bayesian_deep_learning"},{"id": "ising_models"},{"id": "andrychowicz2017_hindsight_experience_replay"},{"id": "single_layer_xor"},{"id": "leaky_integrate_and_fire"},{"id": "multivariable_calculus"},{"id": "c_lang"},{"id": "google_cloud_platform"},{"id": "ios"},{"id": "conversation"},{"id": "investment"},{"id": "information_theory"},{"id": "api_design"},{"id": "ds_algo"},{"id": "robot_motion"},{"id": "experience_replay"},{"id": "laplace_method"},{"id": "policy_gradients"},{"id": "2020-01-24"},{"id": "lu_decomposition"},{"id": "2020-02-03"},{"id": "zador19_critique_pure_learning"},{"id": "markov_localization"},{"id": "gcc"},{"id": "gaussian_processes"},{"id": "rover"},{"id": "artificial_intelligence"},{"id": "software_engineering"},{"id": "pac_learning"},{"id": "books"},{"id": "pomdp"},{"id": "cmake"},{"id": "uncertainty_in_robotics"},{"id": "pgm"},{"id": "spiking_software"},{"id": "wisdom"},{"id": "productivity"},{"id": "consciousness"},{"id": "haskell"},{"id": "rademacher"},{"id": "machine_learning"},{"id": "2020-01-25"},{"id": "zettelkasten"},{"id": "spark"},{"id": "lecun_cake_analogy"},{"id": "fitness"},{"id": "large_batch_training"},{"id": "neuroscience_rl"},{"id": "i-diagrams"},{"id": "slam"},{"id": "model_compression"},{"id": "range_finder_model"},{"id": "writing"},{"id": "2020-01-29"},{"id": "trigger_list"},{"id": "human_behaviour_as_optimal_control"},{"id": "pdf_nup"},{"id": "likelihood_field_model"},{"id": "devops"},{"id": "2020-02-02"},{"id": "imitation_learning"},{"id": "importance_sampling"},{"id": "smoothed_snn"},{"id": "transfer_learning"},{"id": "2020-01-23"},{"id": "antifragile_ideas"},{"id": "art"},{"id": "writing_papers"},{"id": "markov_logic_networks"},{"id": "learning"},{"id": "statistics"},{"id": "extended_kalman_filter"},{"id": "vc_dimension"},{"id": "config_management"},{"id": "running"},{"id": "stochastic_processes"},{"id": "robotics"},{"id": "hugo_setup"},{"id": "systems_programming"},{"id": "bittorrent"},{"id": "robot_kinematics"},{"id": "interval_estimation_bayesian"},{"id": "theory_of_computation"},{"id": "jensens_inequality"},{"id": "surrogate_gradients_snn"},{"id": "nix"},{"id": "two_levels_of_inference"},{"id": "distributed_rl"},{"id": "computer_organization"},{"id": "http"},{"id": "code_litmus_tests"},{"id": "metropolis_hastings"},{"id": "pdf_crop"},{"id": "variational_inference"},{"id": "entropy"},{"id": "evolving_connectionist_systems"},{"id": "synaptic_current_model"},{"id": "dabney2020_distributional_rl"},{"id": "regression"},{"id": "2020-02-01"},{"id": "ger1000"},{"id": "react"},{"id": "generalization_in_rl"},{"id": "2020-02-04"},{"id": "evolving_snn"},{"id": "writing_articles"},{"id": "operating_systems"},{"id": "optimal_control"},{"id": "histogram_filter"},{"id": "studying"},{"id": "mc_methods"},{"id": "feedback_alignment_random_error_bp"},{"id": "generalized_value_functions"},{"id": "bias_complexity_tradeoff"},{"id": "fast_nn_training"},{"id": "credit_assignment_snn"},{"id": "kalman_filter"},{"id": "git"},{"id": "map_matching"},{"id": "point_estimation_bayesian"},{"id": "2020-01-27"},{"id": "meta_learning"},{"id": "blockchain"},{"id": "inverse_rl"},{"id": "hacking"},{"id": "kl_divergence"},{"id": "free_energy_rl"},{"id": "neuroscience_experimental_evidence"},{"id": "random_variables"},{"id": "exploration_in_rl"},{"id": "para_method"},{"id": "state_estimation"},{"id": "spiking_neural_networks"},{"id": "neftci2019_surrogate_gradient_learning_snn"},{"id": "ssnlp"},{"id": "grid_mc_localization"},{"id": "spike_train_mutual_information"},{"id": "occupancy_grid_mapping"},{"id": "henderson_deep_rl_that_matters"},{"id": "2020-01-22"},{"id": "nonparametric_filter"},{"id": "ros"},{"id": "hidden_markov_model"},{"id": "2020-01-31"},{"id": "feeds"},{"id": "css"},{"id": "writing_books"},{"id": "cryptography"},{"id": "cplusplus"},{"id": "ocaml"},{"id": "security"},{"id": "nlp"},{"id": "nn_optimizer"},{"id": "cartographer"},{"id": "data_science"},{"id": "optimization"},{"id": "2020-01-28"},{"id": "is1103"},{"id": "spike_train_metrics"},{"id": "information_filter"},{"id": "deep_rl"},{"id": "information_bottleneck_dnn"},{"id": "eds"},{"id": "2020-02-05"},{"id": "portfolio_composition"},{"id": "2020-01-26"},{"id": "databases"},{"id": "xgboost"},{"id": "mcts"},{"id": "exponential_family"},{"id": "q_learning"},{"id": "ekf_localization"},{"id": "2020-01-17"},{"id": "likelihood_principle"},{"id": "bayes_filter"},{"id": "critical_thinking"},{"id": "sleep"},{"id": "web_dev"},{"id": "arguments_against_zettelkasten"},{"id": "2020-01-21"},{"id": "python"},{"id": "web_dev_tools"},{"id": "miconi_differentiable_plasticity"},{"id": "presentations"},{"id": "actor_critic"},{"id": "data_viz"},{"id": "statistical_learning"},{"id": "comsa2019_temp_coding"},{"id": "linear_algebra"},{"id": "arguments_against_bayesian_inference"},{"id": "normalizing_flows"},{"id": "hadoop"},{"id": "collaborative_editing"},{"id": "td_learning"},{"id": "dl_tools"},{"id": "computer_vision"},{"id": "podcasts"},{"id": "game_api_design"},{"id": "mnih2013_atari_deeprl"},{"id": "markovian_assumption"},{"id": "deep_learning"},{"id": "data_council"},{"id": "lars_optimizer"},{"id": "ges1028"},{"id": "copy_editing"},{"id": "em"},{"id": "docker"},{"id": "control_as_inference"},{"id": "system_design"},{"id": "robotics_probabilistic_generative_laws"},{"id": "velocity_motion_model"},{"id": "recommender_systems"},{"id": "rejection_sampling"},{"id": "information_theoretic_rl"},{"id": "motion_model_with_maps"}],
  "links": [
    {"source": "gibbs_inequality", "target": "kl_divergence", "type": "forward"},
    {"source": "bayesian_inference", "target": "exponential_family", "type": "forward"},
    {"source": "options_framework", "target": "generalized_value_functions", "type": "forward"},
    {"source": "the_art_of_unix_programming", "target": "books", "type": "forward"},
    {"source": "the_art_of_doing_science_and_engineering", "target": "books", "type": "forward"},
    {"source": "are_we_smart_enough_to_know_how_smart_animals_are", "target": "books", "type": "forward"},
    {"source": "reinforcement_learning", "target": "deep_rl", "type": "forward"},
    {"source": "reinforcement_learning", "target": "markov_decision_process", "type": "forward"},
    {"source": "reinforcement_learning", "target": "pomdp", "type": "forward"},
    {"source": "spiking_neurons_lit_review", "target": "comsa2019_temp_coding", "type": "forward"},
    {"source": "hopfield_network", "target": "ising_models", "type": "forward"},
    {"source": "compilers", "target": "theory_of_computation", "type": "forward"},
    {"source": "model_based_rl", "target": "gaussian_processes", "type": "forward"},
    {"source": "occams_razor", "target": "two_levels_of_inference", "type": "forward"},
    {"source": "investment", "target": "portfolio_composition", "type": "forward"},
    {"source": "api_design", "target": "game_api_design", "type": "forward"},
    {"source": "api_design", "target": "code_litmus_tests", "type": "forward"},
    {"source": "robot_motion", "target": "robot_kinematics", "type": "forward"},
    {"source": "pac_learning", "target": "machine_learning", "type": "forward"},
    {"source": "machine_learning", "target": "artificial_intelligence", "type": "forward"},
    {"source": "zettelkasten", "target": "arguments_against_zettelkasten", "type": "forward"},
    {"source": "writing", "target": "presentations", "type": "forward"},
    {"source": "writing", "target": "writing_books", "type": "forward"},
    {"source": "writing", "target": "writing_papers", "type": "forward"},
    {"source": "writing", "target": "writing_articles", "type": "forward"},
    {"source": "writing", "target": "copy_editing", "type": "forward"},
    {"source": "likelihood_field_model", "target": "map_matching", "type": "forward"},
    {"source": "slam", "target": "information_filter", "type": "forward"},
    {"source": "extended_kalman_filter", "target": "information_filter", "type": "forward"},
    {"source": "rademacher", "target": "pac_learning", "type": "forward"},
    {"source": "vc_dimension", "target": "pac_learning", "type": "forward"},
    {"source": "vc_dimension", "target": "bias_complexity_tradeoff", "type": "forward"},
    {"source": "robotics", "target": "cartographer", "type": "forward"},
    {"source": "robotics", "target": "ros", "type": "forward"},
    {"source": "slam", "target": "occupancy_grid_mapping", "type": "forward"},
    {"source": "robotics", "target": "occupancy_grid_mapping", "type": "forward"},
    {"source": "likelihood_field_model", "target": "range_finder_model", "type": "forward"},
    {"source": "robotics", "target": "range_finder_model", "type": "forward"},
    {"source": "robotics", "target": "robot_motion", "type": "forward"},
    {"source": "robotics", "target": "state_estimation", "type": "forward"},
    {"source": "robotics", "target": "uncertainty_in_robotics", "type": "forward"},
    {"source": "interval_estimation_bayesian", "target": "point_estimation_bayesian", "type": "forward"},
    {"source": "surrogate_gradients_snn", "target": "smoothed_snn", "type": "forward"},
    {"source": "two_levels_of_inference", "target": "occams_razor", "type": "forward"},
    {"source": "entropy", "target": "information_theory", "type": "forward"},
    {"source": "entropy", "target": "gibbs_inequality", "type": "forward"},
    {"source": "evolving_connectionist_systems", "target": "evolving_snn", "type": "forward"},
    {"source": "synaptic_current_model", "target": "leaky_integrate_and_fire", "type": "forward"},
    {"source": "evolving_snn", "target": "leaky_integrate_and_fire", "type": "forward"},
    {"source": "mc_methods", "target": "slice_sampling", "type": "forward"},
    {"source": "slice_sampling", "target": "gibbs_sampling", "type": "forward"},
    {"source": "mc_methods", "target": "gibbs_sampling", "type": "forward"},
    {"source": "gibbs_sampling", "target": "metropolis_hastings", "type": "forward"},
    {"source": "slice_sampling", "target": "metropolis_hastings", "type": "forward"},
    {"source": "mc_methods", "target": "metropolis_hastings", "type": "forward"},
    {"source": "slice_sampling", "target": "rejection_sampling", "type": "forward"},
    {"source": "metropolis_hastings", "target": "rejection_sampling", "type": "forward"},
    {"source": "mc_methods", "target": "rejection_sampling", "type": "forward"},
    {"source": "particle_filter", "target": "importance_sampling", "type": "forward"},
    {"source": "policy_gradients", "target": "importance_sampling", "type": "forward"},
    {"source": "metropolis_hastings", "target": "importance_sampling", "type": "forward"},
    {"source": "mc_methods", "target": "importance_sampling", "type": "forward"},
    {"source": "range_finder_model", "target": "likelihood_field_model", "type": "forward"},
    {"source": "map_matching", "target": "likelihood_field_model", "type": "forward"},
    {"source": "inverse_rl", "target": "imitation_learning", "type": "forward"},
    {"source": "para_method", "target": "progressive_summarization", "type": "forward"},
    {"source": "robot_localization", "target": "ekf_localization", "type": "forward"},
    {"source": "grid_mc_localization", "target": "ekf_localization", "type": "forward"},
    {"source": "spike_train_mutual_information", "target": "information_bottleneck_dnn", "type": "forward"},
    {"source": "progressive_summarization", "target": "para_method", "type": "forward"},
    {"source": "2020-01-22", "target": "para_method", "type": "forward"},
    {"source": "nonparametric_filter", "target": "histogram_filter", "type": "forward"},
    {"source": "histogram_filter", "target": "particle_filter", "type": "forward"},
    {"source": "grid_mc_localization", "target": "particle_filter", "type": "forward"},
    {"source": "nonparametric_filter", "target": "particle_filter", "type": "forward"},
    {"source": "css", "target": "web_dev", "type": "forward"},
    {"source": "robotics", "target": "slam", "type": "forward"},
    {"source": "cartographer", "target": "slam", "type": "forward"},
    {"source": "kalman_filter", "target": "extended_kalman_filter", "type": "forward"},
    {"source": "information_filter", "target": "extended_kalman_filter", "type": "forward"},
    {"source": "gaussian_filter", "target": "kalman_filter", "type": "forward"},
    {"source": "extended_kalman_filter", "target": "kalman_filter", "type": "forward"},
    {"source": "information_filter", "target": "kalman_filter", "type": "forward"},
    {"source": "gaussian_filter", "target": "bayes_filter", "type": "forward"},
    {"source": "markov_localization", "target": "bayes_filter", "type": "forward"},
    {"source": "extended_kalman_filter", "target": "bayes_filter", "type": "forward"},
    {"source": "histogram_filter", "target": "bayes_filter", "type": "forward"},
    {"source": "state_estimation", "target": "bayes_filter", "type": "forward"},
    {"source": "nonparametric_filter", "target": "bayes_filter", "type": "forward"},
    {"source": "information_filter", "target": "bayes_filter", "type": "forward"},
    {"source": "deep_rl", "target": "information_theoretic_rl", "type": "forward"},
    {"source": "deep_rl", "target": "exploration_in_rl", "type": "forward"},
    {"source": "deep_rl", "target": "distributed_rl", "type": "forward"},
    {"source": "deep_rl", "target": "transfer_learning", "type": "forward"},
    {"source": "human_behaviour_as_optimal_control", "target": "control_as_inference", "type": "forward"},
    {"source": "inverse_rl", "target": "control_as_inference", "type": "forward"},
    {"source": "deep_rl", "target": "control_as_inference", "type": "forward"},
    {"source": "deep_rl", "target": "inverse_rl", "type": "forward"},
    {"source": "deep_rl", "target": "model_based_rl", "type": "forward"},
    {"source": "reinforcement_learning", "target": "q_learning", "type": "forward"},
    {"source": "transfer_learning", "target": "q_learning", "type": "forward"},
    {"source": "deep_rl", "target": "q_learning", "type": "forward"},
    {"source": "reinforcement_learning", "target": "mcts", "type": "forward"},
    {"source": "optimal_control", "target": "mcts", "type": "forward"},
    {"source": "deep_rl", "target": "mcts", "type": "forward"},
    {"source": "investment", "target": "investing_in_etfs", "type": "forward"},
    {"source": "portfolio_composition", "target": "investing_in_etfs", "type": "forward"},
    {"source": "options_framework", "target": "td_learning", "type": "forward"},
    {"source": "reinforcement_learning", "target": "td_learning", "type": "forward"},
    {"source": "q_learning", "target": "td_learning", "type": "forward"},
    {"source": "distributed_rl", "target": "mnih2013_atari_deeprl", "type": "forward"},
    {"source": "q_learning", "target": "mnih2013_atari_deeprl", "type": "forward"},
    {"source": "reinforcement_learning", "target": "actor_critic", "type": "forward"},
    {"source": "q_learning", "target": "actor_critic", "type": "forward"},
    {"source": "robot_localization", "target": "grid_mc_localization", "type": "forward"},
    {"source": "ekf_localization", "target": "grid_mc_localization", "type": "forward"},
    {"source": "robot_localization", "target": "markov_localization", "type": "forward"},
    {"source": "grid_mc_localization", "target": "markov_localization", "type": "forward"},
    {"source": "ekf_localization", "target": "markov_localization", "type": "forward"},
    {"source": "slam", "target": "robot_localization", "type": "forward"},
    {"source": "robotics", "target": "robot_localization", "type": "forward"},
    {"source": "state_estimation", "target": "robot_localization", "type": "forward"},
    {"source": "occupancy_grid_mapping", "target": "robot_localization", "type": "forward"},
    {"source": "ekf_localization", "target": "robot_localization", "type": "forward"},
    {"source": "kalman_filter", "target": "gaussian_filter", "type": "forward"},
    {"source": "information_filter", "target": "gaussian_filter", "type": "forward"},
    {"source": "bayes_filter", "target": "gaussian_filter", "type": "forward"},
    {"source": "robotics", "target": "robotics_probabilistic_generative_laws", "type": "forward"},
    {"source": "bayes_filter", "target": "robotics_probabilistic_generative_laws", "type": "forward"},
    {"source": "reinforcement_learning", "target": "markovian_assumption", "type": "forward"},
    {"source": "policy_gradients", "target": "markovian_assumption", "type": "forward"},
    {"source": "kalman_filter", "target": "markovian_assumption", "type": "forward"},
    {"source": "bayes_filter", "target": "markovian_assumption", "type": "forward"},
    {"source": "web_dev", "target": "web_dev_tools", "type": "forward"},
    {"source": "web_dev", "target": "http", "type": "forward"},
    {"source": "web_dev", "target": "css", "type": "forward"},
    {"source": "para_method", "target": "zettelkasten", "type": "forward"},
    {"source": "arguments_against_zettelkasten", "target": "zettelkasten", "type": "forward"},
    {"source": "zador19_critique_pure_learning", "target": "meta_learning", "type": "forward"},
    {"source": "miconi_differentiable_plasticity", "target": "meta_learning", "type": "forward"},
    {"source": "reinforcement_learning", "target": "policy_gradients", "type": "forward"},
    {"source": "deep_rl", "target": "policy_gradients", "type": "forward"},
    {"source": "q_learning", "target": "policy_gradients", "type": "forward"},
    {"source": "actor_critic", "target": "policy_gradients", "type": "forward"},
    {"source": "spiking_neurons_lit_review", "target": "spiking_neural_networks", "type": "forward"},
    {"source": "spiking_datasets", "target": "spiking_neural_networks", "type": "forward"},
    {"source": "spiking_software", "target": "spiking_neural_networks", "type": "forward"},
    {"source": "credit_assignment_snn", "target": "spiking_neural_networks", "type": "forward"},
    {"source": "neuroscience_experimental_evidence", "target": "spiking_neural_networks", "type": "forward"},
    {"source": "neftci2019_surrogate_gradient_learning_snn", "target": "spiking_neural_networks", "type": "forward"},
    {"source": "spike_train_mutual_information", "target": "spiking_neural_networks", "type": "forward"},
    {"source": "spike_train_metrics", "target": "spiking_neural_networks", "type": "forward"},
    {"source": "comsa2019_temp_coding", "target": "spiking_neural_networks", "type": "forward"},
    {"source": "lu_decomposition", "target": "linear_algebra", "type": "forward"},
    {"source": "computer_vision", "target": "linear_algebra", "type": "forward"},
    {"source": "lecun_cake_analogy", "target": "andrychowicz2017_hindsight_experience_replay", "type": "forward"},
    {"source": "mnih2013_atari_deeprl", "target": "andrychowicz2017_hindsight_experience_replay", "type": "forward"},
    {"source": "mnih2013_atari_deeprl", "target": "experience_replay", "type": "forward"},
    {"source": "gpipe", "target": "fast_nn_training", "type": "forward"},
    {"source": "2020-02-05", "target": "fast_nn_training", "type": "forward"},
    {"source": "lars_optimizer", "target": "fast_nn_training", "type": "forward"},
    {"source": "gpipe", "target": "large_batch_training", "type": "forward"},
    {"source": "2020-02-05", "target": "large_batch_training", "type": "forward"},
    {"source": "lars_optimizer", "target": "large_batch_training", "type": "forward"},
    {"source": "lars_optimizer", "target": "nn_optimizer", "type": "forward"},
    {"source": "human_behaviour_as_optimal_control", "target": "optimal_control", "type": "forward"},
    {"source": "control_as_inference", "target": "optimal_control", "type": "forward"},
    {"source": "human_behaviour_as_optimal_control", "target": "reinforcement_learning", "type": "forward"},
    {"source": "dabney2020_distributional_rl", "target": "reinforcement_learning", "type": "forward"},
    {"source": "control_as_inference", "target": "reinforcement_learning", "type": "forward"},
    {"source": "control_as_inference", "target": "hidden_markov_model", "type": "forward"},
    {"source": "control_as_inference", "target": "pgm", "type": "forward"},
    {"source": "velocity_motion_model", "target": "motion_model_with_maps", "type": "forward"},
    {"source": "robot_kinematics", "target": "odometry_motion_model", "type": "forward"},
    {"source": "velocity_motion_model", "target": "odometry_motion_model", "type": "forward"},
    {"source": "motion_model_with_maps", "target": "odometry_motion_model", "type": "forward"},
    {"source": "odometry_motion_model", "target": "velocity_motion_model", "type": "forward"},
    {"source": "robot_kinematics", "target": "velocity_motion_model", "type": "forward"},
    {"source": "motion_model_with_maps", "target": "velocity_motion_model", "type": "forward"}
  ]
}

types = ["forward"];
color = d3.scaleOrdinal(types, d3.schemeCategory10);

function linkArc(d) {
  const r = Math.hypot(d.target.x - d.source.x, d.target.y - d.source.y);
  return `
    M${d.source.x},${d.source.y}
    A${r},${r} 0 0,1 ${d.target.x},${d.target.y}
  `;
}

drag = simulation => {
  function dragstarted(d) {
    if (!d3.event.active) simulation.alphaTarget(0.3).restart();
    d.fx = d.x;
    d.fy = d.y;
  }
  function dragged(d) {
    d.fx = d3.event.x;
    d.fy = d3.event.y;
  }
  function dragended(d) {
    if (!d3.event.active) simulation.alphaTarget(0);
    d.fx = null;
    d.fy = null;
  }
  return d3.drag()
           .on("start", dragstarted)
           .on("drag", dragged)
           .on("end", dragended);
}

const links = data.links.map(d => Object.create(d));
const nodes = data.nodes.map(d => Object.create(d));

const simulation = d3.forceSimulation(nodes)
                     .force("link", d3.forceLink(links).id(d => d.id))
                     .force("charge", d3.forceManyBody().strength(-400))
                     .force("x", d3.forceX())
                     .force("y", d3.forceY());

const svg = d3.select("body")
              .append("svg")
              .attr("width", "100%")
              .attr("height", "100%")
              .style("font", "12px sans-serif");

svg.call(d3.zoom().on("zoom", function () {
  svg.attr("transform", d3.event.transform)
})).append("g");

// Per-type markers, as they don't inherit styles.
svg.append("defs").selectAll("marker")
   .data(types)
   .join("marker")
   .attr("id", d => `arrow-${d}`)
   .attr("viewBox", "0 -5 10 10")
   .attr("refX", 15)
   .attr("refY", -0.5)
   .attr("markerWidth", 6)
   .attr("markerHeight", 6)
   .attr("orient", "auto")
   .append("path")
   .attr("fill", color)
   .attr("d", "M0,-5L10,0L0,5");

const link = svg.append("g")
                .attr("fill", "none")
                .attr("stroke-width", 1.5)
                .selectAll("path")
                .data(links)
                .join("path")
                .attr("stroke", d => color(d.type))
                .attr("marker-end", d => `url(${new URL(`#arrow-${d.type}`, location)})`);

const node = svg.append("g")
                .attr("fill", "currentColor")
                .attr("stroke-linecap", "round")
                .attr("stroke-linejoin", "round")
                .selectAll("g")
                .data(nodes)
                .join("g")
                .call(drag(simulation));

node.append("circle")
    .attr("stroke", "white")
    .attr("stroke-width", 1.5)
    .attr("r", 4);

node.append("text")
    .attr("x", 8)
    .attr("y", "0.31em")
    .text(d => d.id)
    .clone(true).lower()
    .attr("fill", "none")
    .attr("stroke", "white")
    .attr("stroke-width", 3);

simulation.on("tick", () => {
  link.attr("d", linkArc);
  node.attr("transform", d => `translate(${d.x},${d.y})`);
});
